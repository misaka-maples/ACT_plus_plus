# from datetime import datetime
import os, datetime, sys
import threading
import time
import json
import threading
import serial
import numpy as np
import cv2
from queue import Queue
from pyorbbecsdk import *
from utils import frame_to_bgr_image

MAX_DEVICES = 5  # ÂÅáËÆæÊúÄÂ§öÊîØÊåÅ 5 Âè∞ËÆæÂ§á
MAX_QUEUE_SIZE = 10  # ÊúÄÂ§ßÂ∏ßÈòüÂàóÈïøÂ∫¶
multi_device_sync_config = {}
config_file_path = os.path.join(os.path.dirname(__file__), "./config/multi_device_sync_config.json")
from networkx.readwrite.json_graph.tree import tree_data
from triton.language.semantic import store
from deploy.hdf5_edit_utils import Modify_hdf5
from deploy.policy_action_generation import ActionGenerator
import numpy as np
import math
from tqdm import tqdm
from deploy.visualize_episodes import visualize_joints
from tcp_tx import PersistentClient
import pytz
tz = pytz.timezone('Asia/Shanghai')
current_time = datetime.datetime.now(tz)
# datetime.
JOINT_NAMES = ["joint1", "joint2", "joint3", "joint4", "joint5", "joint6"]
STATE_NAMES = JOINT_NAMES +["gripper_pos"]+ ["gripper_force"]
camera_names = ['top', 'right_wrist','left_wrist']

class CAMERA_HOT_PLUG:
    def __init__(self):
        self.mutex = threading.Lock()
        self.ctx = Context()
        self.device_list = self.ctx.query_devices()
        self.curr_device_cnt = self.device_list.get_count()
        self.pipelines: list[Pipeline] = []
        self.configs: list[Config] = []
        self.serial_number_list: list[str] = ["" for _ in range(self.curr_device_cnt)]
        self.color_frames_queue: dict[str, Queue] = {}
        self.depth_frames_queue: dict[str, Queue] = {}

        self.setup_cameras()
        self.start_streams()
        print("Áõ∏Êú∫ÂàùÂßãÂåñÂÆåÊàê")

        # ÁõëÊéßËÆæÂ§áÁ∫øÁ®ã
        self.monitor_thread = threading.Thread(target=self.monitor_devices, daemon=True)
        self.monitor_thread.start()

    def monitor_devices(self):
        """ÂÆöÊúüÊ£ÄÊü•Áõ∏Êú∫ËøûÊé•Áä∂ÊÄÅ"""
        while True:
            time.sleep(2)
            new_device_list = self.ctx.query_devices()
            new_device_cnt = new_device_list.get_count()

            if new_device_cnt != self.curr_device_cnt:
                print("ËÆæÂ§áÂèòÂåñÊ£ÄÊµãÂà∞ÔºåÈáçÊñ∞ÂàùÂßãÂåñÁõ∏Êú∫...")
                self.stop_streams()
                self.device_list = new_device_list
                self.curr_device_cnt = new_device_cnt
                self.setup_cameras()
                self.start_streams()

    def setup_cameras(self):
        """ÂàùÂßãÂåñÁõ∏Êú∫ËÆæÂ§á"""
        self.read_config(config_file_path)

        if self.curr_device_cnt == 0:
            print("‚ö†Ô∏è No device connected")
            return
        if self.curr_device_cnt > MAX_DEVICES:
            print("‚ö†Ô∏è Too many devices connected")
            return

        for i in range(self.curr_device_cnt):
            device = self.device_list.get_device_by_index(i)
            serial_number = device.get_device_info().get_serial_number()

            self.color_frames_queue[serial_number] = Queue()
            self.depth_frames_queue[serial_number] = Queue()
            pipeline = Pipeline(device)
            config = Config()

            # ËØªÂèñÂêåÊ≠•ÈÖçÁΩÆ
            sync_config_json = multi_device_sync_config.get(serial_number, {})
            sync_config = device.get_multi_device_sync_config()
            sync_config.mode = self.sync_mode_from_str(sync_config_json["config"]["mode"])
            sync_config.color_delay_us = sync_config_json["config"]["color_delay_us"]
            sync_config.depth_delay_us = sync_config_json["config"]["depth_delay_us"]
            sync_config.trigger_out_enable = sync_config_json["config"]["trigger_out_enable"]
            sync_config.trigger_out_delay_us = sync_config_json["config"]["trigger_out_delay_us"]
            sync_config.frames_per_trigger = sync_config_json["config"]["frames_per_trigger"]
            device.set_multi_device_sync_config(sync_config)

            try:
                profile_list = pipeline.get_stream_profile_list(OBSensorType.COLOR_SENSOR)
                color_profile = profile_list.get_default_video_stream_profile()
                config.enable_stream(color_profile)

                profile_list = pipeline.get_stream_profile_list(OBSensorType.DEPTH_SENSOR)
                depth_profile = profile_list.get_default_video_stream_profile()
                config.enable_stream(depth_profile)

                self.pipelines.append(pipeline)
                self.configs.append(config)
                self.serial_number_list[i] = serial_number
            except OBError as e:
                print(f"setup_cameras error: {e}")

    def start_streams(self):
        """ÂêØÂä®Áõ∏Êú∫ÊµÅ"""
        print(self.serial_number_list)
        for index, (pipeline, config, serial) in enumerate(zip(self.pipelines, self.configs, self.serial_number_list)):
            pipeline.start(
                config,
                lambda frame_set, curr_serial=serial: self.on_new_frame_callback(frame_set, curr_serial),
            )

    def stop_streams(self):
        """ÂÅúÊ≠¢Áõ∏Êú∫ÊµÅ"""
        with self.mutex:
            try:
                for pipeline in self.pipelines:
                    pipeline.stop()
                self.pipelines = []
                self.configs = []
                print("üì∑ Devices stopped")
            except Exception as e:
                print(f"‚ö†Ô∏è Error stopping streams: {e}")

    def on_new_frame_callback(self, frames: FrameSet, serial_number: str):
        """Êé•Êî∂Êñ∞Â∏ßÂπ∂Â≠òÂÖ•ÈòüÂàó"""
        with self.mutex:
            if serial_number not in self.color_frames_queue:
                print(f"‚ö†Ô∏è WARN: Êú™ËØÜÂà´ÁöÑÁõ∏Êú∫Â∫èÂàóÂè∑ {serial_number}ÔºåË∑≥ËøáÂ∏ßÂ§ÑÁêÜ")
                return

            color_frame = frames.get_color_frame()
            depth_frame = frames.get_depth_frame()

            if color_frame:
                if self.color_frames_queue[serial_number].qsize() >= MAX_QUEUE_SIZE:
                    self.color_frames_queue[serial_number].get()
                self.color_frames_queue[serial_number].put(color_frame)

            if depth_frame:
                if self.depth_frames_queue[serial_number].qsize() >= MAX_QUEUE_SIZE:
                    self.depth_frames_queue[serial_number].get()
                self.depth_frames_queue[serial_number].put(depth_frame)

    def rendering_frame(self, max_wait=5):
        image_dict: dict[str, np.ndarray] = {}
        start_time = time.time()
        color_width, color_height = None, None
        while len(image_dict) != self.curr_device_cnt:
            if time.time() - start_time > max_wait:
                print("‚ö†Ô∏è WARN: Ê∏≤ÊüìË∂ÖÊó∂ÔºåÈÉ®ÂàÜÁõ∏Êú∫Êú™Êî∂Âà∞Â∏ßÊï∞ÊçÆ")
                break
            for serial_number in self.color_frames_queue.keys():
                color_frame = None
                if not self.color_frames_queue[serial_number].empty():
                    color_frame = self.color_frames_queue[serial_number].get()
                if color_frame is None:
                    continue
                color_width, color_height = color_frame.get_width(), color_frame.get_height()
                color_image = frame_to_bgr_image(color_frame)
                image_dict[serial_number] = color_image

        return image_dict,color_width, color_height

    def sync_mode_from_str(self, sync_mode_str: str) -> OBMultiDeviceSyncMode:
        """Â∞ÜÂ≠óÁ¨¶‰∏≤ËΩ¨Êç¢‰∏∫ÂêåÊ≠•Ê®°Âºè"""
        sync_mode_str = sync_mode_str.upper()
        sync_modes = {
            "FREE_RUN": OBMultiDeviceSyncMode.FREE_RUN,
            "STANDALONE": OBMultiDeviceSyncMode.STANDALONE,
            "PRIMARY": OBMultiDeviceSyncMode.PRIMARY,
            "SECONDARY": OBMultiDeviceSyncMode.SECONDARY,
            "SECONDARY_SYNCED": OBMultiDeviceSyncMode.SECONDARY_SYNCED,
            "SOFTWARE_TRIGGERING": OBMultiDeviceSyncMode.SOFTWARE_TRIGGERING,
            "HARDWARE_TRIGGERING": OBMultiDeviceSyncMode.HARDWARE_TRIGGERING,
        }
        return sync_modes.get(sync_mode_str, OBMultiDeviceSyncMode.FREE_RUN)

    def read_config(self, config_file: str):
        """ËØªÂèñÈÖçÁΩÆÊñá‰ª∂"""
        global multi_device_sync_config
        with open(config_file, "r") as f:
            config = json.load(f)
        for device in config["devices"]:
            multi_device_sync_config[device["serial_number"]] = device
            print(f"üì∑ Device {device['serial_number']}: {device['config']['mode']}")


class GPCONTROL(threading.Thread):
    def __init__(self, DEFAULT_SERIAL_PORTS=("/dev/ttyACM0", "/dev/ttyACM1", "/dev/ttyACM2")):
        super().__init__()
        self.state_flag = 128
        self.running = True
        self.control_command = ""
        self.DEFAULT_SERIAL_PORTS = DEFAULT_SERIAL_PORTS
        self.BAUD_RATE = 50000
        self.id = 1
        self.min_data = b'\x00\x00\xFF\xFF\xFF\xFF\x00\x00'
        self.max_data = b'\x00\xFF\xFF\xFF\xFF\xFF\x00\x00'
        self.ser = self.open_serial()
        self.is_sending = False
        self.state_data_1 = 128
        self.state_data_2 = 0
        self.task_complete = False
        self.is_configured = False
        self.state = ()
        # ÂàùÂßãÂåñCANËÆæÁΩÆ
        self.send_data(b'\x49\x3B\x42\x57\x01\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x45\x2E')
        self.send_data(b'\x49\x3B\x42\x57\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x45\x2E')
        self.read_data()
        self.send_data(b'\x49\x3B\x44\x57\x01\x00\x01\x01\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x45\x2E')
        self.read_data()

    def run(self):
        while self.running:
            # print(f"self.state_data_1:{self.state_data_1}\n,self.state_data_2:{self.state_data_2}")
            if self.state_data_1<0:
                self.state_data_1=0
            if self.state_data_2<0:
                self.state_data_2=0
            state_1 = self.set_gp_state(self.state_data_1, can_id=0)
            state_2 = self.set_gp_state(self.state_data_2, can_id=1)
            self.state = [state_1,state_2]
            time.sleep(0.2)
    def open(self):
        self.state_data_2=255
    def close_(self):
        self.state_data_2=0
    def stop(self):
        self.running = False
        print("[INFO] Gripper thread stopping...")

    def open_serial(self):
        for port in self.DEFAULT_SERIAL_PORTS:
            try:
                ser = serial.Serial(port, self.BAUD_RATE, timeout=1)
                print(f"‰∏≤Âè£ {port} Â∑≤ÊâìÂºÄÔºåÊ≥¢ÁâπÁéá {self.BAUD_RATE}")
                return ser
            except Exception as e:
                print(f"Êó†Ê≥ïÊâìÂºÄ‰∏≤Âè£ {port}: {e}")
        print(f"Êó†Ê≥ïÊâìÂºÄ‰ªª‰Ωï‰∏≤Âè£: {', '.join(self.DEFAULT_SERIAL_PORTS)}")

    def set_state_flag(self,value,id):
        """‰øÆÊîπ self.state_flag"""
        self.state_data_1 = value[0]
        self.state_data_2 = value[1]
        self.id = id

    def send_data(self, data):
        """ÂèëÈÄÅÊï∞ÊçÆÂà∞‰∏≤Âè£"""
        ser=self.ser
        if ser and ser.is_open:
            ser.write(data)
            # print(f"ÂèëÈÄÅÊï∞ÊçÆ: {data.hex()}")
        else:
            print("‰∏≤Âè£Êú™ÊâìÂºÄÔºåÊó†Ê≥ïÂèëÈÄÅÊï∞ÊçÆ")


    def filter_can_data(self, data):
        """Ê†πÊçÆÂ§¥Ôºà0x5AÔºâÂíåÂ∞æÔºà0xA5ÔºâËøáÊª§Êï∞ÊçÆ"""
        valid_frames = []

        # Êü•ÊâæÊâÄÊúâ‰ª• 0x5A ÂºÄÂ§¥Âπ∂‰ª• 0xA5 ÁªìÂ∞æÁöÑÊï∞ÊçÆÂ∏ß
        start_idx = 0
        while start_idx < len(data):
            # Êü•Êâæ‰∏ã‰∏Ä‰∏™0x5A
            start_idx = data.find(b'\x5A', start_idx)
            if start_idx == -1:  # Â¶ÇÊûúÊâæ‰∏çÂà∞0x5AÔºåÈÄÄÂá∫Âæ™ÁéØ
                break

            # Êü•Êâæ‰∏ã‰∏Ä‰∏™0xA5
            end_idx = data.find(b'\xA5', start_idx)
            if end_idx == -1:  # Â¶ÇÊûúÊâæ‰∏çÂà∞0xA5ÔºåÈÄÄÂá∫Âæ™ÁéØ
                break

            # ÊèêÂèñÊúâÊïàÊï∞ÊçÆÂ∏ßÔºàÂåÖÊã¨0x5AÂíå0xA5Ôºâ
            frame = data[start_idx:end_idx + 1]

            # Á°Æ‰øùÊï∞ÊçÆÂ∏ßÈïøÂ∫¶ÂêàÁêÜÔºàËá≥Â∞ë 8 Â≠óËäÇÔºâ
            if len(frame) >= 8:
                valid_frames.append(frame)

            # ËÆæÁΩÆËµ∑ÂßãÁ¥¢ÂºïÔºåÁªßÁª≠Êü•Êâæ‰∏ã‰∏Ä‰∏™Â∏ß
            start_idx = end_idx + 1
        return valid_frames

    def read_data(self):
        """ËØªÂèñ‰∏≤Âè£ËøîÂõûÊï∞ÊçÆÂπ∂ËøáÊª§Á¨¶ÂêàÂ§¥Â∞æË¶ÅÊ±ÇÁöÑÊï∞ÊçÆ"""
        ser = self.ser
        if ser and ser.is_open:
            data = ser.read(32)  # ËØªÂèñÊúÄÂ§ß 64 Â≠óËäÇ
            if data:
                valid_frames = self.filter_can_data(data)
                if valid_frames:
                    back_data=0
                    for frame in valid_frames:
                        if frame[:2].hex()=='5aff':
                            # print("")
                            continue
                        else:
                            # print(f"Êé•Êî∂Á¨¶ÂêàÊù°‰ª∂ÁöÑCANÊï∞ÊçÆ: {frame.hex()}")
                            back_data=frame.hex()
                    return valid_frames, back_data
                else:
                    pass
            else:
                print("Êú™Êî∂Âà∞Êï∞ÊçÆ")
        else:
            print("‰∏≤Âè£Êú™ÊâìÂºÄÔºåÊó†Ê≥ïËØªÂèñÊï∞ÊçÆ")
        return None
    def send_can_data(self, can_id, data, channel):
        """
        ÂèëÈÄÅ CAN Êï∞ÊçÆÂ∏ß
        :param ser: ‰∏≤Âè£ÂØπË±°
        :param can_id: 4Â≠óËäÇ CAN ID
        :param data: ÂèëÈÄÅÊï∞ÊçÆÔºåÊúÄÂ§ß 64 Â≠óËäÇ
        """
        can_id_bytes = can_id  # CAN ID ËΩ¨Êç¢Êàê 4Â≠óËäÇ

        data_length = len(data)
        if data_length > 64:
            data = data[:64]  # ÈôêÂà∂Êï∞ÊçÆÈïøÂ∫¶‰∏∫ 64 Â≠óËäÇ
        channel = channel & 0x01  # Á°Æ‰øù channel Âè™Êúâ1‰Ωç
        frame_header = b'\x5A'  # Â∏ßÂ§¥
        frame_info_1 = (data_length | channel << 7).to_bytes(1, 'big')  # CANÈÄöÈÅì0, DLCÊï∞ÊçÆÈïøÂ∫¶
        frame_info_2 = b'\x00'  # ÂèëÈÄÅÁ±ªÂûã: Ê≠£Â∏∏ÂèëÈÄÅ, Ê†áÂáÜÂ∏ß, Êï∞ÊçÆÂ∏ß, ‰∏çÂä†ÈÄü
        frame_data = data.ljust(64, b'\x00')  # Êï∞ÊçÆÂ°´ÂÖÖÂà∞ 64 Â≠óËäÇ
        frame_end = b'\xA5'  # Â∏ßÂ∞æ

        send_frame = frame_header + frame_info_1 + frame_info_2 + can_id_bytes + frame_data[:data_length] + frame_end
        # print("ÂèëÈÄÅ CAN Â∏ß:", send_frame.hex())
        self.send_data(send_frame)
        # _,data = self.read_data()
        # return data
    def open_half_gp(self):
        half_open_gp = b'\x00\x7f\xFF\xFF\xFF\xFF\x00\x00'
        while 1:
            self.send_can_data(b'\x00\x00\x00\x01', half_open_gp, 0x01)
            data = self.read_data() 
            if data is not None:
                _, gpdata = data
                while gpdata == 0:
                    self.send_can_data(b'\x00\x00\x00\x01', half_open_gp, 0x01)
                    data = self.read_data()
                    if data is not None:
                        _, gpdata = data
                gpstate,gppos,gpforce = gpdata[16:18],gpdata[18:20],gpdata[22:24]
                return [gpstate,gppos,gpforce]
        
    def open_all_gp(self):
        self.state_data_2=255
        open_gp = b'\x00\xff\xFF\xFF\xFF\xFF\x00\x00'
        while 1:
            self.send_can_data(b'\x00\x00\x00\x01', open_gp, 0x01)
            data = self.read_data() 
            if data is not None:
                _, gpdata = data
                while gpdata == 0:
                    self.send_can_data(b'\x00\x00\x00\x01', open_gp, 0x01)
                    data = self.read_data()
                    if data is not None:
                        _, gpdata = data
                gpstate,gppos,gpforce = gpdata[16:18],gpdata[18:20],gpdata[22:24]
                return [gpstate,gppos,gpforce]
    def set_gp_state(self,value,can_id=1):
        assert 0 <= value <= 255, "value must be between 0 and 255"
        open_gp = b'\x00' + value.to_bytes(1, 'big') + b'\xFF\xFF\xFF\xFF\x00\x00'
        
        while 1:
            self.send_can_data(b'\x00\x00\x00\x01', open_gp, can_id)
            data = self.read_data() 
            if data is not None:
                _, gpdata = data
                while gpdata == 0:
                    self.send_can_data(b'\x00\x00\x00\x01', open_gp, can_id)
                    data = self.read_data()
                    if data is not None:
                        _, gpdata = data
                gpstate,gppos,gpforce = gpdata[16:18],gpdata[18:20],gpdata[22:24]
                return [gpstate,gppos,gpforce]
    def close_gp(self):
        close_gp = b'\x00\x00\xFF\xFF\xFF\xFF\x00\x00'
        while 1:
            self.send_can_data(b'\x00\x00\x00\x01', close_gp, 0x01)
            data = self.read_data() 
            if data is not None:
                _, gpdata = data
                while gpdata == 0:
                    self.send_can_data(b'\x00\x00\x00\x01', close_gp, 0x01)
                    data = self.read_data()
                    if data is not None:
                        _, gpdata = data
                gpstate,gppos,gpforce = gpdata[16:18],gpdata[18:20],gpdata[22:24]
                return [gpstate,gppos,gpforce]
        
    def control_gp(self, gpstate, gppos, gpforce):
        gpstate = gpstate.to_bytes(2, 'big')
        gppos = gppos.to_bytes(2, 'big')
        gpforce = gpforce.to_bytes(2, 'big')
        gpcontrol_data = b'\x00\x00' + gpstate + gppos + b'\x00\x00' + gpforce
        print(f"gpcontrol_data: {gpcontrol_data.hex()}")
            
        while 1:   
            self.send_can_data(b'\x00\x00\x00\x01', gpcontrol_data, 0x01)
            data = self.read_data()
            if data is not None:
                _, gpdata = data
                while gpdata == 0:
                    self.send_can_data(b'\x00\x00\x00\x01', gpcontrol_data, 0x01)
                    data = self.read_data()
                    if data is not None:
                        _, gpdata = data
                gpstate,gppos,gpforce = gpdata[16:18],gpdata[18:20],gpdata[22:24]
                return [gpstate,gppos,gpforce]
            # return data
    
    def close(self):
        if self.ser:
            self.ser.close()


class eval:
    def __init__(self,real_robot=False,data_true=False):
        self.real_robot = real_robot
        self.data_true = data_true
        if self.real_robot:
            self.camera = CAMERA_HOT_PLUG()
            self.persistentClient = PersistentClient('192.168.3.15', 8001)
            self.image = {'top': [], 'right_wrist': [], 'left_wrist':[]}
            self.main()
        else:
            self.main()
    
    def updata_frame(self):
        """Êõ¥Êñ∞ÊëÑÂÉèÂ§¥ÂõæÂÉè"""
        global multi_device_sync_config
        frame_data, color_width, color_height = self.camera.rendering_frame()
        serial_number_list = self.camera.serial_number_list
        camera_index_map = {device['config']['camera_name']: serial_number_list.index(device["serial_number"]) for device in multi_device_sync_config.values() if device["serial_number"] in serial_number_list}

        # print(f"frame_data: {type(frame_data)}")
        # print(frame_data[serial_number_list[0]].shape)
        # Âà§Êñ≠ frame_data ÁöÑÁ±ªÂûã
        if isinstance(frame_data, dict):  # Â§öÂè∞ÊëÑÂÉèÂ§¥ËøîÂõûÂ≠óÂÖ∏ {str: np.ndarray}
            if not frame_data:  # Â≠óÂÖ∏‰∏∫Á©∫
                print("‚ö†Ô∏è WARN: Ê≤°ÊúâÊé•Êî∂Âà∞‰ªª‰ΩïÊëÑÂÉèÂ§¥ÂõæÂÉè")
                return
            if all(img.size == 0 for img in frame_data.values()):  # ÊâÄÊúâÁõ∏Êú∫ÁöÑÂõæÂÉèÈÉΩÊòØÁ©∫ÁöÑ
                print("‚ö†Ô∏è WARN: ÊâÄÊúâÊëÑÂÉèÂ§¥ÁöÑÂõæÂÉèÊï∞ÊçÆ‰∏∫Á©∫")
                return
            # print(f"‚ö†Ô∏è WARN: Â§öÂè∞ÊëÑÂÉèÂ§¥ÔºåÂ∫èÂàóÂè∑ÂàóË°®: {serial_number_list}")
        elif isinstance(frame_data, np.ndarray):  # Âè™Êúâ‰∏ÄÂè∞Áõ∏Êú∫
            if frame_data.size == 0:
                print("‚ö†Ô∏è WARN: Ê≤°ÊúâÊé•Êî∂Âà∞‰ªª‰ΩïÊëÑÂÉèÂ§¥ÂõæÂÉè")
                return
            # Âè™Êúâ‰∏Ä‰∏™ÊëÑÂÉèÂ§¥Êó∂ÔºåÂ∞ÜÂÖ∂Â≠òÂÖ•Â≠óÂÖ∏ÔºåÊ®°ÊãüÂ§öÊëÑÂÉèÂ§¥Ê†ºÂºè
            frame_data = {"0": frame_data}  
            serial_number_list = ["0"]
            print(f"‚ö†Ô∏è WARN: Âè™Êúâ‰∏ÄÂè∞ÊëÑÂÉèÂ§¥ÔºåÂ∫èÂàóÂè∑‰∏∫ {serial_number_list[0]}")
        else:
            print(f"‚ö†Ô∏è ERROR: Êó†ÊïàÁöÑ frame_data Á±ªÂûã: {type(frame_data)}")
            return
        # ÂàùÂßãÂåñÁªìÊûúÂõæÂÉè
        num_images = len(frame_data)
        result_image = None
        for device in multi_device_sync_config.values():
            cam_name, sn = device['config']['camera_name'], device["serial_number"]
            if sn in frame_data:
                img = frame_data[sn]
                if result_image is None:
                    result_image = img  # Á¨¨‰∏Ä‰∏™ÊëÑÂÉèÂ§¥ÁöÑÂõæÂÉè
                else:
                    result_image = np.hstack((result_image, img))  # ÊåâÊ∞¥Âπ≥ÊñπÂêëÊãºÊé•ÂõæÂÉè
            else:
                print(f"‚ö†Ô∏è WARN: ÊëÑÂÉèÂ§¥ {cam_name}Ôºà{sn}ÔºâÁöÑÂõæÂÉèÊï∞ÊçÆÁº∫Â§±")

        if result_image is not None:
            # Ë∞ÉÊï¥Â§ßÂ∞èÂπ∂ÊòæÁ§∫ÂõæÂÉè
            result_image = cv2.resize(result_image, (color_width, color_height))
            # self.display_image(result_image)
            for camera_name in camera_names:
                self.image[camera_name] = frame_data.get(str(serial_number_list[camera_index_map[camera_name]]))
            # self.image['top'] = frame_data.get(str(serial_number_list[camera_index_map['top']]), None)
            # self.image['right_wrist'] = frame_data.get(str(serial_number_list[camera_index_map['right_wrist']]), None) if num_images > 1 else None
    def is_close(self, actual, target, tolerance=0.1):
        """
        Âà§Êñ≠‰∏§‰∏™ÂàóË°®ÁöÑÊØè‰∏™ÂÖÉÁ¥†ÊòØÂê¶Âú®ÂÖÅËÆ∏ËØØÂ∑ÆËåÉÂõ¥ÂÜÖ
        :param actual: ÂÆûÈôÖÂÄºÂàóË°®ÔºàÂ¶ÇÂΩìÂâçÊú∫Ê¢∞ËáÇÁä∂ÊÄÅÔºâ
        :param target: ÁõÆÊ†áÂÄºÂàóË°®
        :param tolerance: ÂÖÅËÆ∏ÁöÑÊúÄÂ§ßËØØÂ∑ÆÔºàÁªùÂØπÂÄºÔºâ
        :return: ÊâÄÊúâÂÖÉÁ¥†ÂùáÊª°Ë∂≥ËØØÂ∑ÆË¶ÅÊ±ÇËøîÂõûTrueÔºåÂê¶ÂàôFalse
        """
        # Â§ÑÁêÜNoneÂíåÈïøÂ∫¶Ê£ÄÊü•
        if actual is None or target is None:
            return False
        if len(actual) != len(target):
            return False
        
        # ÈÄê‰∏™ÂÖÉÁ¥†ÊØîËæÉËØØÂ∑Æ
        for a, t in zip(actual, target):
            if abs(a - t) > tolerance:
                return False
        return True
    def main(self):
        actions_list = []
        qpos_list_ = []
        loss = []
        self.radius_qpos_list = []

        if self.data_true:
            self.gp_contrpl = GPCONTROL()
            self.gp_contrpl.start()
            loop_len = 200
            task_complete_step = None
            square_size = 100
        else:
            data_dict = Modify_hdf5()
            dict_ = data_dict.check_hdf5(r'/workspace/exchange/5-9/exchange/episode_10.hdf5')
            # print(dict_["action"].shape)
            loop_len = len(dict_['top'])
        config = {
            'ckpt_dir': r'/workspace/exchange/5-9/exchange/act',
            'max_timesteps': loop_len,
            'ckpt_name': "policy_step_30000_seed_0.ckpt",
            'backbone': 'resnet18',
            'temporal_agg':True,
        }
        image_dict = {i:[] for i in camera_names}
        # print(image_dict)
        ActionGeneration = ActionGenerator(config)
        for i in tqdm(range(loop_len)):
            # print(f"roll:{i}")
            ActionGeneration.t = i
            if self.real_robot:
                if self.data_true:
                    self.updata_frame()
                    left_qpos = self.persistentClient.get_arm_position_joint(1)
                    right_qpos = self.persistentClient.get_arm_position_joint(2)
                    left_gp ,right_gp= self.gp_contrpl.state
                    # left_pos=left_gp[1]
                    # left_force = left_gp[2]
                    # right_pos=right_gp[1]
                    # right_force = right_gp[2]
                    # print(left_gp)
                    radius_qpos = [math.radians(j) for j in left_qpos]
                    gpstate, gppos, gpforce = map(lambda x: str(x) if not isinstance(x, str) else x, left_gp)
                    radius_qpos.extend([int(gppos, 16), int(gpforce, 16)])
                    radius_qpos.extend([math.radians(j) for j in right_qpos])
                    gpstate, gppos, gpforce = map(lambda x: str(x) if not isinstance(x, str) else x, right_gp)
                    radius_qpos.extend([int(gppos, 16), int(gpforce, 16)])
                    # radius_qpos.append(left_pos)
                    # radius_qpos.append(left_force)
                    # radius_qpos.append(right_qpos)
                    # radius_qpos.append(right_pos)
                    # radius_qpos.append(right_force)
                    # print(radius_qpos)
                    # if self.is_close(self.persistentClient.get_arm_position_joint(1)[:3],[-121.42, -599.741, -209.687]) or i >30:
                    #     task_complete_step = 1
                    for camera_name in camera_names:
                        image_dict[camera_name] = self.image[camera_name]
                        # qpos = self.persistentClient.get_arm_position_joint(1)
                        # radius_qpos = [math.radians(j) for j in qpos]
                        # img_copy = [row[:] for row in image_dict[camera_name]]  # Ê∑±Êã∑Ë¥ùÔºåÈò≤Ê≠¢ÊîπÂà∞ÂéüÂõæ
                        # height = len(img_copy)
                        # width = len(img_copy[0])
                        # print(height,width)
                        # square_color = [0, 0, 255] if task_complete_step is  None else [0, 255, 0]  
                        # if square_color == [0,0,255]:
                        #     print("Á∫¢Ëâ≤")
                        # elif  square_color == [0, 255, 0]:
                        #     print("ÁªøËâ≤")
                        # # Â∑¶‰∏ãËßíÔºöË°åËåÉÂõ¥ [height - square_size, height)
                        # for row in range(height - square_size, height):
                        #     for col in range(square_size):
                        #         if 0 <= row < height and 0 <= col < width:
                        #             img_copy[row][col] = square_color
                        # image_dict[camera_name] = np.array(img_copy)
                else:
                    for camera_name in camera_names:
                        image_dict[camera_name]=np.array(dict_[camera_name][i])
                        # qpos = self.persistentClient.get_arm_position_joint(1)
                        # radius_qpos = [math.radians(j) for j in qpos]
                        radius_qpos = dict_['qpos'][i]
            else:
                
                for camera_name in camera_names:
                    image_dict[camera_name] = np.array(dict_[camera_name][i])
                radius_qpos = dict_['qpos'][i]
            # print(np.array(radius_qpos).shape)
            self.radius_qpos_list.append(radius_qpos)
            # print(image_dict)
            ActionGeneration.image_dict = image_dict
            ActionGeneration.qpos_list = radius_qpos
            actions = ActionGeneration.get_action()
            # print(qpos)
            # print(list(np.degrees(actions)))
            left_arm_action = np.rad2deg(actions[:6])
            right_arm_action= np.rad2deg(actions[8:14])
            left_gp = actions[6:8]*0.4
            right_gp = 120-actions[14:16]
            # print(left_gp,right_gp)
            # print(actions[6:8],actions[14:16])
            # print(left_arm_action,right_arm_action)
            if self.real_robot:
                if right_arm_action[5]>360:
                    right_arm_action[5]=358
                self.persistentClient.set_arm_position(list(right_arm_action), "joint", 2)
                self.persistentClient.set_arm_position(list(left_arm_action), "joint", 1)
                print(int(left_gp[0]),int(right_gp[0]))
                self.gp_contrpl.state_data_1=int(left_gp[0])
                self.gp_contrpl.state_data_2=int(right_gp[0])
            actions_list.append(actions)
            # loss.append((actions - dict_['action'][i]) ** 2)
        today = current_time.strftime("%m-%d-%H-%M")
        path_save_image = os.path.join(os.getcwd(), "deploy_image", f"{today}")
        os.makedirs(path_save_image, exist_ok=True)
        image_path = os.path.join(path_save_image, config['backbone']+"_"+ os.path.splitext(config['ckpt_name'])[0]+ ".png")
        loss_apth = os.path.join(path_save_image, 'loss' + current_time.strftime("%m-%d+8-%H-%M") + ".png")
       
        visualize_joints(self.radius_qpos_list, actions_list, image_path, STATE_NAMES=STATE_NAMES)

if __name__ == '__main__':
    eval(real_robot=False,data_true=False)